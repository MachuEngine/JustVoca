# backend/app/api/study.py
from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Depends
from pydantic import BaseModel
from sqlmodel import Session, select
import shutil
import os
import pandas as pd
from typing import List, Optional
import random
from datetime import datetime, timedelta

from app.core.database import get_session
from app.models import StudyProgress, StudyLog, User

router = APIRouter()

# ì—‘ì…€ íŒŒì¼ ê²½ë¡œ ì„¤ì •
CURRENT_FILE_PATH = os.path.abspath(__file__)
BACKEND_DIR = os.path.dirname(os.path.dirname(os.path.dirname(CURRENT_FILE_PATH)))
EXCEL_PATH = os.path.join(BACKEND_DIR, "data", "vocab", "vocabulary.xlsx")

class WordSchema(BaseModel):
    id: int
    level: str
    topic: str
    word: str
    meaning: str
    eng_meaning: str
    example: str
    audio_path: str # ì˜¤ë””ì˜¤ ì •ë³´ í¬í•¨

# ê¸°ë³¸ ë§¤í•‘ (ê³ ì • ì»¬ëŸ¼)
COLUMN_MAPPING = {
    "ì£¼ì œ": "topic", 
    "ë‹¨ì–´": "word", 
    "ë¶„ë¥˜": "meaning", 
    "CEFR Level": "eng_meaning", 
    "ì˜ˆë¬¸1": "example"
}

@router.get("/current-progress")
async def get_current_progress(user_id: str, db: Session = Depends(get_session)):
    statement = select(StudyProgress).where(StudyProgress.user_id == user_id).order_by(StudyProgress.updated_at.desc())
    progress = db.exec(statement).first()
    if not progress:
        return {"level": "ì´ˆê¸‰1", "current_page": 1}
    return {"level": progress.level, "current_page": progress.current_page}

@router.get("/words", response_model=List[WordSchema])
async def get_words(
    level: str = "ì´ˆê¸‰1", 
    user_id: Optional[str] = None, 
    db: Session = Depends(get_session)
):
    if not os.path.exists(EXCEL_PATH):
        return []

    try:
        current_page = 1
        if user_id:
            user = db.get(User, user_id)
            if not user:
                user = User(uid=user_id, name=user_id, role="student")
                db.add(user)
                db.commit()
            
            statement = select(StudyProgress).where(StudyProgress.user_id == user_id, StudyProgress.level == level)
            progress = db.exec(statement).first()
            if progress:
                current_page = progress.current_page

        xls = pd.ExcelFile(EXCEL_PATH, engine="openpyxl")
        target_sheet = next((s for s in xls.sheet_names if s.replace(" ", "") == level.replace(" ", "")), None)
        
        if not target_sheet:
            target_sheet = random.choice(xls.sheet_names)
            
        df = pd.read_excel(xls, sheet_name=target_sheet)
        
        # --- [ì˜¤ë””ì˜¤ ì»¬ëŸ¼ ìœ ì—°í•œ ë§¤í•‘ ë¡œì§ ì¶”ê°€] ---
        actual_cols = df.columns.tolist()
        # "Audio_Voca" ë˜ëŠ” "íŒŒì¼ ëª…"ì´ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ì»¬ëŸ¼ì„ ì°¾ìŠµë‹ˆë‹¤.
        audio_col = next((c for c in actual_cols if "Audio_Voca" in str(c) or "íŒŒì¼ ëª…" in str(c)), None)
        
        # ì°¾ì€ ì˜¤ë””ì˜¤ ì»¬ëŸ¼ì„ audio_pathë¡œ ì´ë¦„ ë³€ê²½
        temp_mapping = COLUMN_MAPPING.copy()
        if audio_col:
            temp_mapping[audio_col] = "audio_path"
            
        df = df.rename(columns=temp_mapping)

        # í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš° ë¹ˆ ê°’ ìƒì„±
        required_fields = list(COLUMN_MAPPING.values()) + ["audio_path"]
        for col in required_fields:
            if col not in df.columns: df[col] = ""
        
        df = df.fillna("")

        start_idx = (current_page - 1) * 10
        if start_idx >= len(df): start_idx = 0 
        paged_df = df.iloc[start_idx : start_idx + 10].copy()
        
        if 'level' not in paged_df.columns: paged_df['level'] = target_sheet
        if 'topic' not in paged_df.columns: paged_df['topic'] = "General"

        data_list = paged_df.to_dict(orient="records")
        for idx, item in enumerate(data_list):
            item['id'] = start_idx + idx + 1
            item['word'] = str(item.get('word', ''))
            item['meaning'] = str(item.get('meaning', ''))
            item['eng_meaning'] = str(item.get('eng_meaning', ''))
            item['example'] = str(item.get('example', ''))
            item['audio_path'] = str(item.get('audio_path', '')) # ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ í™•ì‹¤íˆ ë³€í™˜

        return data_list

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Data Load Error: {str(e)}")

@router.post("/evaluate")
async def evaluate_pronunciation(
    file: UploadFile = File(...), 
    word: str = Form(...),
    user_id: str = Form(...), 
    db: Session = Depends(get_session)
):
    upload_dir = "temp_uploads"
    os.makedirs(upload_dir, exist_ok=True)
    file_path = os.path.join(upload_dir, file.filename)
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    
    score = random.randint(75, 100)
    feedback = "ì°¸ ì˜í–ˆì–´ìš”!" if score > 85 else "ì¡°ê¸ˆë§Œ ë” í˜ë‚´ì„¸ìš”!"
    new_log = StudyLog(user_id=user_id, word=word, score=float(score), feedback=feedback)
    db.add(new_log)
    db.commit()

    return {"status": "success", "score": score, "feedback": feedback, "recognized_text": word}

@router.post("/complete")
async def complete_step(user_id: str = Form(...), level: str = Form(...), db: Session = Depends(get_session)):
    statement = select(StudyProgress).where(StudyProgress.user_id == user_id, StudyProgress.level == level)
    progress = db.exec(statement).first()
    if progress:
        progress.current_page += 1
        progress.updated_at = datetime.now()
        db.add(progress)
    else:
        new_progress = StudyProgress(user_id=user_id, level=level, current_page=2)
        db.add(new_progress)
    db.commit()
    return {"status": "success", "next_page": progress.current_page if progress else 2}


# app/api/study.py (ê¸°ì¡´ ì½”ë“œ í•˜ë‹¨ì— ì¶”ê°€)

@router.get("/review-words")
async def get_review_words(user_id: str, db: Session = Depends(get_session)):
    """
    [ë³µìŠµ ê¸°ëŠ¥]
    ìµœê·¼ í•™ìŠµ ë¡œê·¸ ì¤‘ ì ìˆ˜ê°€ ë‚®ì€ ìˆœì„œëŒ€ë¡œ ìµœëŒ€ 5ê°œ ë‹¨ì–´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    # 1. ì‚¬ìš©ìì˜ í•™ìŠµ ë¡œê·¸ ì¡°íšŒ (ì ìˆ˜ ë‚®ì€ ìˆœ)
    statement = select(StudyLog).where(StudyLog.user_id == user_id).order_by(StudyLog.score.asc()).limit(5)
    logs = db.exec(statement).all()
    
    if not logs:
        return []

    # 2. ë¡œê·¸ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (í”„ë¡ íŠ¸ì—”ë“œ Word íƒ€ì…ì— ë§ì¶¤)
    review_list = []
    for log in logs:
        review_list.append({
            "id": log.id,
            "word": log.word,
            "meaning": "", # ë¡œê·¸ì—ëŠ” ëœ»ì´ ì—†ìœ¼ë¯€ë¡œ ë¹ˆê°’ í˜¹ì€ DB êµ¬ì¡° ë³€ê²½ í•„ìš” (ì—¬ê¸°ì„  ë¹ˆê°’ ì²˜ë¦¬)
            "eng_meaning": "",
            "example": "",
            "audio_path": "",
            "level": "",
            "topic": "Review"
        })
    return review_list

@router.get("/quiz")
async def get_quiz(level: str = "ì´ˆê¸‰1"):
    """
    [í€´ì¦ˆ ê¸°ëŠ¥]
    í•´ë‹¹ ë ˆë²¨ì˜ ì—‘ì…€ ë°ì´í„°ì—ì„œ ëœë¤í•˜ê²Œ 3ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not os.path.exists(EXCEL_PATH):
        return []

    try:
        # 1. ì—‘ì…€ ë¡œë“œ
        xls = pd.ExcelFile(EXCEL_PATH, engine="openpyxl")
        target_sheet = next((s for s in xls.sheet_names if s.replace(" ", "") == level.replace(" ", "")), None)
        if not target_sheet:
            target_sheet = xls.sheet_names[0]
            
        df = pd.read_excel(xls, sheet_name=target_sheet).fillna("")
        
        # ì»¬ëŸ¼ ë§¤í•‘ (ë‹¨ì–´, ì˜ë¯¸ ì°¾ê¸°)
        df = df.rename(columns=COLUMN_MAPPING)
        
        # ë°ì´í„°ê°€ ì ìœ¼ë©´ ì „ì²´ ì‚¬ìš©, ë§ìœ¼ë©´ 3ê°œ ìƒ˜í”Œë§
        sample_size = min(3, len(df))
        quiz_samples = df.sample(n=sample_size).to_dict(orient="records")
        
        quizzes = []
        for i, item in enumerate(quiz_samples):
            correct_word = str(item.get('word', ''))
            description = str(item.get('meaning', item.get('ëœ»', '')))
            
            # ì˜¤ë‹µ ë³´ê¸° 3ê°œ ìƒì„± (ì •ë‹µì´ ì•„ë‹Œ ê²ƒ ì¤‘ì—ì„œ ëœë¤ ìƒ˜í”Œë§)
            distractors = df[df['word'] != correct_word]['word'].sample(n=3).tolist()
            options = distractors + [correct_word]
            random.shuffle(options)
            
            quizzes.append({
                "id": i + 1,
                "question": description, # ì˜ˆ: "ê°€ê¹ê²Œ ì˜¤ë˜ ì‚¬ê·„ ì‚¬ëŒ"
                "answer": correct_word,  # ì˜ˆ: "ì¹œêµ¬"
                "options": options       # ["ì¹œêµ¬", "í•™êµ", "ê³µë¶€", "ìš´ë™"]
            })
            
        return quizzes

    except Exception as e:
        print(f"Quiz generation error: {e}")
        return []


# [ì‹ ê·œ ì¶”ê°€] í†µê³„ API ì—”ë“œí¬ì¸íŠ¸
@router.get("/stats")
async def get_student_stats(user_id: str, db: Session = Depends(get_session)):
    """
    í•™ìƒ ê°œì¸ í•™ìŠµ í†µê³„ ì¡°íšŒ (ì‚¬ì–‘ì„œ ê¸°ë°˜)
    """
    # 1. í•™ìƒì˜ ëª¨ë“  í•™ìŠµ ë¡œê·¸ ì¡°íšŒ (ìµœì‹ ìˆœ)
    logs = db.exec(select(StudyLog).where(StudyLog.user_id == user_id).order_by(StudyLog.created_at.desc())).all()
    
    # 2. ì´ë²ˆ ì£¼(ìµœê·¼ 7ì¼) í•™ìŠµí•œ ë‹¨ì–´ ìˆ˜ ê³„ì‚°
    now = datetime.now()
    seven_days_ago = now - timedelta(days=7)
    
    # ìµœê·¼ 7ì¼ ë‚´ì˜ ë¡œê·¸ë§Œ í•„í„°ë§
    weekly_logs = [log for log in logs if log.created_at >= seven_days_ago]
    # ì¤‘ë³µ ë‹¨ì–´ë¥¼ ì œì™¸í•˜ê³  ê°œìˆ˜ ì„¸ê¸° (set ì´ìš©)
    weekly_learned_count = len({log.word for log in weekly_logs})
    
    # 3. ì „ì²´ í‰ê·  ì •í™•ë„ ê³„ì‚°
    avg_accuracy = 0
    if logs:
        total_score = sum(log.score for log in logs)
        avg_accuracy = int(total_score / len(logs))
    
    # 4. ì—°ì† í•™ìŠµì¼(Streak) ê³„ì‚°
    streak = 0
    if logs:
        # ë¡œê·¸ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œí•˜ì—¬ ì¤‘ë³µ ì œê±° í›„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        dates = sorted(list({log.created_at.date() for log in logs}), reverse=True)
        today = now.date()
        
        # ê°€ì¥ ìµœê·¼ í•™ìŠµì¼ì´ ì˜¤ëŠ˜ì´ê±°ë‚˜ ì–´ì œì—¬ì•¼ ì—°ì† í•™ìŠµìœ¼ë¡œ ì¸ì •
        if dates and (today - dates[0]).days <= 1:
            streak = 1
            # ê³¼ê±° ë‚ ì§œë“¤ì„ ë¹„êµí•˜ë©° ì—°ì† ì—¬ë¶€ í™•ì¸
            for i in range(len(dates) - 1):
                if (dates[i] - dates[i+1]).days == 1:
                    streak += 1
                else:
                    break
    
    # 5. ì£¼ê°„ í•™ìŠµ ì¶”ì´ (ì›”~ì¼)
    # 0:ì›”ìš”ì¼, ... 6:ì¼ìš”ì¼
    weekly_trend = [0] * 7
    
    # ì´ë²ˆ ì£¼ì˜ ì‹œì‘ì¼(ì›”ìš”ì¼) êµ¬í•˜ê¸°
    start_of_week = now.date() - timedelta(days=now.weekday())
    
    for log in logs:
        log_date = log.created_at.date()
        # ë¡œê·¸ ë‚ ì§œê°€ ì´ë²ˆ ì£¼(ì›”~ì¼) ë²”ìœ„ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
        if start_of_week <= log_date <= (start_of_week + timedelta(days=6)):
            day_idx = log_date.weekday() # 0(ì›”) ~ 6(ì¼)
            weekly_trend[day_idx] += 1
            
    # ê·¸ë˜í”„ í‘œí˜„ì„ ìœ„í•´ ê°€ì¥ ë§ì´ í•™ìŠµí•œ ë‚ ì„ 100%ë¡œ ì¡ê³  ì •ê·œí™”
    max_val = max(weekly_trend) if max(weekly_trend) > 0 else 1
    normalized_trend = [int((val / max_val) * 100) for val in weekly_trend]

    # 6. ìˆ™ë ¨ë„ (ì ìˆ˜ êµ¬ê°„ë³„ ë¶„í¬)
    total_count = len(logs) if logs else 1
    high_count = len([l for l in logs if l.score >= 90])      # 90ì  ì´ìƒ: ì™„ì „ ì•”ê¸°
    mid_count = len([l for l in logs if 70 <= l.score < 90])  # 70~89ì : ë³µìŠµ í•„ìš”
    low_count = len([l for l in logs if l.score < 70])        # 70ì  ë¯¸ë§Œ: ë‹¤ì‹œ í•™ìŠµ
    
    proficiency = [
        {"label": "ì™„ì „ ì•”ê¸°", "value": int((high_count / total_count) * 100), "color": "bg-green-500"},
        {"label": "ë³µìŠµ í•„ìš”", "value": int((mid_count / total_count) * 100), "color": "bg-orange-400"},
        {"label": "ë‹¤ì‹œ í•™ìŠµ", "value": int((low_count / total_count) * 100), "color": "bg-red-400"},
    ]

    # ì‘ì› ë©”ì‹œì§€ ì„¤ì •
    message = "ì´ë²ˆ ì£¼ ëª©í‘œ ë‹¬ì„± ì¤‘! ğŸ”¥" if weekly_learned_count > 0 else "í•™ìŠµì„ ì‹œì‘í•´ë³´ì„¸ìš”! ğŸ’ª"

    return {
        "weeklyLearned": weekly_learned_count,
        "streak": streak,
        "accuracy": avg_accuracy,
        "weeklyTrend": normalized_trend,
        "proficiency": proficiency,
        "message": message
    }